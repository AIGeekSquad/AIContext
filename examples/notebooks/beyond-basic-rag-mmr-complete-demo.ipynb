{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Marginal Relevance (MMR) for .NET RAG Systems\n",
    "\n",
    "This notebook demonstrates **Maximum Marginal Relevance (MMR)** - a technique that balances relevance with diversity to solve the clustering problem in RAG systems.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Why traditional RAG returns repetitive results\n",
    "- MMR theory and implementation\n",
    "- Microsoft.Extensions.AI integration\n",
    "- Production patterns and parameter tuning\n",
    "\n",
    "Let's build better RAG systems with diverse, relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "**Ollama Setup:**\n",
    "- Install Ollama from [https://ollama.ai](https://ollama.ai)\n",
    "- Start service: `ollama serve`\n",
    "- Pull model: `ollama pull all-minilm`\n",
    "\n",
    "**Alternative:** For production, use Azure OpenAI or other MEAI-compatible providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Install required NuGet packages\n",
    "#r \"nuget: MathNet.Numerics, 5.0.0\"\n",
    "#r \"nuget: AiGeekSquad.AIContext, *-*\"\n",
    "#r \"nuget: AiGeekSquad.AIContext.MEAI, *-*\"\n",
    "#r \"nuget: OllamaSharp, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.AI.Abstractions, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.AI, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.DependencyInjection, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Logging, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Logging.Console, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Caching.Memory, *-*\"\n",
    "\n",
    "using System;\n",
    "using OllamaSharp;\n",
    "using System.Collections.Generic;\n",
    "using System.Linq;\n",
    "using System.Threading;\n",
    "using System.Threading.Tasks;\n",
    "using Microsoft.Extensions.AI;\n",
    "using Microsoft.Extensions.DependencyInjection;\n",
    "using Microsoft.Extensions.Logging;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using Microsoft.Extensions.Caching.Memory;\n",
    "using MathNet.Numerics.LinearAlgebra;\n",
    "using MathNet.Numerics;\n",
    "using AiGeekSquad.AIContext.Ranking;\n",
    "using AiGeekSquad.AIContext.Chunking;\n",
    "using AiGeekSquad.AIContext.MEAI;\n",
    "using IEmbeddingGenerator = Microsoft.Extensions.AI.IEmbeddingGenerator;\n",
    "\n",
    "Console.WriteLine(\"✅ Packages loaded successfully!\");\n",
    "Console.WriteLine($\"📦 MathNet.Numerics: {typeof(MathNet.Numerics.Control).Assembly.GetName().Version}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEAI Service Configuration\n",
    "\n",
    "Microsoft.Extensions.AI provides a standardized abstraction for embedding generation with provider flexibility and built-in resilience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "IEmbeddingGenerator<string,Embedding<float>> embeddingGenerator = \n",
    "    new OllamaApiClient(\"http://localhost:11434\", \"all-minilm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Context Selection Problem\n",
    "\n",
    "RAG systems face a fundamental constraint: limited context windows. When you can only include a few documents, each one needs to add unique value.\n",
    "\n",
    "**The Problem:** Traditional semantic search clusters around similar topics, wasting context space with repetitive information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Semantic Search Falls Short\n",
    "\n",
    "Traditional RAG uses semantic search to find the most relevant documents, creating a clustering problem where highly similar documents dominate results.\n",
    "\n",
    "**Example:** Query \"optimizing application performance\" returns three documents about memory management, nothing about databases or caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// E-commerce search demonstrating the clustering problem\n",
    "var products = new[]\n",
    "{\n",
    "    new { Name = \"Sony WH-1000XM4 Wireless Headphones\", Similarity = 0.95, Category = \"Audio\" },\n",
    "    new { Name = \"Bose QuietComfort Wireless Headphones\", Similarity = 0.93, Category = \"Audio\" },\n",
    "    new { Name = \"Apple AirPods Pro Wireless Earbuds\", Similarity = 0.91, Category = \"Audio\" },\n",
    "    new { Name = \"Wireless Phone Charger\", Similarity = 0.45, Category = \"Accessories\" },\n",
    "    new { Name = \"Bluetooth Speaker\", Similarity = 0.42, Category = \"Audio\" },\n",
    "    new { Name = \"USB-C Cable\", Similarity = 0.15, Category = \"Accessories\" }\n",
    "};\n",
    "\n",
    "Console.WriteLine(\"Query: 'wireless headphones'\");\n",
    "Console.WriteLine(\"\\nTraditional search (top 3 most similar):\");\n",
    "\n",
    "var traditionalResults = products\n",
    "    .OrderByDescending(p => p.Similarity)\n",
    "    .Take(3);\n",
    "    \n",
    "foreach (var product in traditionalResults)\n",
    "{\n",
    "    Console.WriteLine($\"• {product.Name} (similarity: {product.Similarity})\");\n",
    "}\n",
    "\n",
    "var uniqueCategories = traditionalResults.Select(p => p.Category).Distinct().Count();\n",
    "Console.WriteLine($\"\\nProblem: Only {uniqueCategories} category represented - missing accessories!\");\n",
    "Console.WriteLine(\"Traditional search returns three similar headphones but misses complementary accessories customers often need.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Marginal Relevance Explained\n",
    "\n",
    "MMR balances two goals:\n",
    "1. **Relevance** - How well does a document match your query?\n",
    "2. **Diversity** - How different is it from documents you've already selected?\n",
    "\n",
    "### The Formula\n",
    "```\n",
    "MMR Score = λ × Relevance + (1-λ) × Diversity\n",
    "```\n",
    "\n",
    "**Lambda (λ) Parameter:**\n",
    "- **λ = 1.0**: Pure relevance (traditional search)\n",
    "- **λ = 0.7**: Balanced (recommended starting point)\n",
    "- **λ = 0.5**: Equal balance\n",
    "- **λ = 0.0**: Pure diversity\n",
    "\n",
    "Start with λ = 0.7 for most applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with MEAI\n",
    "\n",
    "Let's implement MMR with Microsoft.Extensions.AI integration to solve the clustering problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Customer support: \"app crashes on startup\"\n",
    "// This example demonstrates MMR solving a customer support scenario\n",
    "\n",
    "// Generate embeddings for solution categories using MEAI\n",
    "var solutionTexts = new[]\n",
    "{\n",
    "    \"Clear app cache and data to resolve startup issues\",\n",
    "    \"Restart the application to fix temporary glitches\", \n",
    "    \"Reinstall the app to fix corrupted installation\",\n",
    "    \"Check system requirements and compatibility\",\n",
    "    \"Update device drivers for hardware compatibility\",\n",
    "    \"Contact technical support for advanced troubleshooting\"\n",
    "};\n",
    "\n",
    "Console.WriteLine(\"🔄 Generating embeddings using MEAI...\");\n",
    "\n",
    "// Generate embeddings for all solutions\n",
    "var solutionEmbeddings = new List<(string solution, Vector<double> embedding)>();\n",
    "foreach (var solution in solutionTexts)\n",
    "{\n",
    "    var embeddingResult = await embeddingGenerator.GenerateVectorAsync(solution);\n",
    "    var embedding = Vector<double>.Build.DenseOfArray(embeddingResult.ToArray().Select(f => (double)f).ToArray());\n",
    "    solutionEmbeddings.Add((solution, embedding));\n",
    "}\n",
    "\n",
    "// Generate query embedding\n",
    "var queryText = \"app crashes on startup\";\n",
    "var queryEmbeddingResult = await embeddingGenerator.GenerateVectorAsync(queryText);\n",
    "var queryEmbedding = Vector<double>.Build.DenseOfArray(queryEmbeddingResult.ToArray().Select(f => (double)f).ToArray());\n",
    "\n",
    "Console.WriteLine($\"✅ Generated embeddings for {solutionEmbeddings.Count} solutions\");\n",
    "Console.WriteLine($\"📊 Embedding dimensions: {queryEmbedding.Count}\");\n",
    "\n",
    "Console.WriteLine(\"\\n=== Support Ticket: 'App won't start' ===\");\n",
    "\n",
    "// Traditional search (most similar)\n",
    "Console.WriteLine(\"\\n🔍 BEFORE - Traditional Search (top 3):\");\n",
    "var traditionalSupport = solutionEmbeddings\n",
    "    .Select((sol, idx) => new { \n",
    "        Index = idx, \n",
    "        Solution = sol.solution, \n",
    "        Similarity = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), sol.embedding.ToArray()) \n",
    "    })\n",
    "    .OrderByDescending(x => x.Similarity)\n",
    "    .Take(3);\n",
    "\n",
    "foreach (var result in traditionalSupport)\n",
    "{\n",
    "    Console.WriteLine($\"• {result.Solution} (similarity: {result.Similarity:F3})\");\n",
    "}\n",
    "\n",
    "// MMR search (balanced relevance and diversity)\n",
    "Console.WriteLine(\"\\n✨ AFTER - MMR Search (λ = 0.7):\");\n",
    "var mmrResults = MaximumMarginalRelevance.ComputeMMR(\n",
    "    vectors: solutionEmbeddings.Select(s => s.embedding).ToList(),\n",
    "    query: queryEmbedding,\n",
    "    lambda: 0.7,\n",
    "    topK: 3\n",
    ");\n",
    "\n",
    "foreach (var (index, score) in mmrResults)\n",
    "{\n",
    "    var solution = solutionEmbeddings[index].solution;\n",
    "    var similarity = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), solutionEmbeddings[index].embedding.ToArray());\n",
    "    Console.WriteLine($\"• {solution} (similarity: {similarity:F3}, MMR score: {score:F3})\");\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"\\n✅ MMR provides diverse troubleshooting approaches instead of repetitive similar solutions!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Lambda Values\n",
    "\n",
    "The lambda parameter controls the relevance-diversity balance:\n",
    "\n",
    "| Lambda | Balance | Best For |\n",
    "|:------:|:--------|:---------|\n",
    "| **0.9** | High relevance | FAQ systems, troubleshooting |\n",
    "| **0.7** | Balanced (recommended) | General-purpose RAG |\n",
    "| **0.5** | Equal balance | Research, comparative analysis |\n",
    "| **0.3** | High diversity | Content discovery, brainstorming |\n",
    "\n",
    "**Domain recommendations:**\n",
    "- Customer Support: λ = 0.8\n",
    "- Research Tools: λ = 0.6\n",
    "- Content Discovery: λ = 0.4\n",
    "- Technical Docs: λ = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Interactive lambda exploration\n",
    "// Let's see how different lambda values affect the same query\n",
    "\n",
    "void TestLambdaValue(double lambda, string description)\n",
    "{\n",
    "    Console.WriteLine($\"\\n🎯 Lambda = {lambda} ({description}):\");\n",
    "    \n",
    "    var results = MaximumMarginalRelevance.ComputeMMR(\n",
    "        vectors: solutionEmbeddings.Select(s => s.embedding).ToList(),\n",
    "        query: queryEmbedding,\n",
    "        lambda: lambda,\n",
    "        topK: 3\n",
    "    );\n",
    "    \n",
    "    var categories = new HashSet<string>();\n",
    "    foreach (var (index, score) in results)\n",
    "    {\n",
    "        var solution = solutionEmbeddings[index].solution;\n",
    "        var similarity = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), solutionEmbeddings[index].embedding.ToArray());\n",
    "        Console.WriteLine($\"   • {solution} (similarity: {similarity:F3})\");\n",
    "        \n",
    "        // Categorize solutions for analysis\n",
    "        if (solution.Contains(\"cache\") || solution.Contains(\"restart\") || solution.Contains(\"reinstall\"))\n",
    "            categories.Add(\"basic_fixes\");\n",
    "        else if (solution.Contains(\"system\") || solution.Contains(\"driver\"))\n",
    "            categories.Add(\"system_issues\");\n",
    "        else if (solution.Contains(\"support\"))\n",
    "            categories.Add(\"escalation\");\n",
    "    }\n",
    "    \n",
    "    Console.WriteLine($\"   📊 Solution categories covered: {categories.Count} ({string.Join(\", \", categories)})\");\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"🎛️ LAMBDA PARAMETER EXPLORATION\");\n",
    "Console.WriteLine(\"Let's see how different lambda values affect our support ticket results:\");\n",
    "\n",
    "TestLambdaValue(1.0, \"Pure Relevance - Traditional Search\");\n",
    "TestLambdaValue(0.8, \"High Relevance - Customer Support Recommended\");\n",
    "TestLambdaValue(0.7, \"Balanced - General Purpose\");\n",
    "TestLambdaValue(0.5, \"Equal Balance - Research/Analysis\");\n",
    "TestLambdaValue(0.3, \"High Diversity - Content Discovery\");\n",
    "TestLambdaValue(0.0, \"Pure Diversity - Maximum Variety\");\n",
    "\n",
    "Console.WriteLine(\"\\n💡 Key Insight: Higher lambda values focus on relevance, lower values increase diversity.\");\n",
    "Console.WriteLine(\"   For most applications, λ = 0.7 provides the best balance!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Patterns\n",
    "\n",
    "This section demonstrates enterprise-grade patterns for production RAG systems:\n",
    "\n",
    "### Key Features\n",
    "1. **Two-Stage Retrieval** - Scalable pattern for millions of documents\n",
    "2. **Adaptive Lambda Selection** - Dynamic parameter tuning\n",
    "3. **Enterprise Caching** - Multi-level caching strategy\n",
    "4. **Comprehensive Observability** - Request tracking and metrics\n",
    "5. **Dependency Injection** - Clean, testable architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Supporting classes for production RAG service\n",
    "public class DocumentCandidate\n",
    "{\n",
    "    public string Id { get; set; }\n",
    "    public string Title { get; set; }\n",
    "    public string Content { get; set; }\n",
    "    public Vector<double> Embedding { get; set; }\n",
    "    public double Score { get; set; }\n",
    "}\n",
    "\n",
    "public class RAGResponse\n",
    "{\n",
    "    public string RequestId { get; set; }\n",
    "    public string Answer { get; set; }\n",
    "    public List<DocumentCandidate> SourceDocuments { get; set; } = new();\n",
    "    public double Lambda { get; set; }\n",
    "    public string Domain { get; set; }\n",
    "    public bool FromCache { get; set; }\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"✅ Supporting classes defined!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Production-ready RAG service with MMR integration\n",
    "public class ProductionRAGService\n",
    "{\n",
    "    private readonly IEmbeddingGenerator<string,Embedding<float>> _embeddingGenerator;\n",
    "    private readonly IMemoryCache _cache;\n",
    "    private readonly ILogger _logger;\n",
    "    private readonly List<DocumentCandidate> _documents;\n",
    "    \n",
    "    public ProductionRAGService(IEmbeddingGenerator<string,Embedding<float>> embeddingGenerator, IMemoryCache cache, ILogger logger)\n",
    "    {\n",
    "        _embeddingGenerator = embeddingGenerator;\n",
    "        _cache = cache;\n",
    "        _logger = logger;\n",
    "        _documents = GenerateDocumentDatabase();\n",
    "    }\n",
    "    \n",
    "    public async Task<RAGResponse> AskQuestionAsync(string question, string domain = \"general\")\n",
    "    {\n",
    "        var requestId = Guid.NewGuid().ToString(\"N\")[..8];\n",
    "        _logger.LogInformation(\"Processing question {RequestId}: {Question} (domain: {Domain})\", \n",
    "            requestId, question, domain);\n",
    "        \n",
    "        // 1. Check cache first\n",
    "        var cacheKey = $\"{domain}:{question.GetHashCode():X}\";\n",
    "        if (_cache.TryGetValue(cacheKey, out RAGResponse cachedResponse))\n",
    "        {\n",
    "            _logger.LogInformation(\"Cache hit for {RequestId}\", requestId);\n",
    "            cachedResponse.FromCache = true;\n",
    "            return cachedResponse;\n",
    "        }\n",
    "        \n",
    "        // 2. Generate query embedding\n",
    "        var queryEmbedding = await _embeddingGenerator.GenerateVectorAsync(question);\n",
    "        \n",
    "        // Convert embedding to Vector<double>\n",
    "        var queryVector = Vector<double>.Build.DenseOfArray(\n",
    "            queryEmbedding.ToArray().Select(x => (double)x).ToArray());\n",
    "        \n",
    "        // 3. Two-stage retrieval: Cast wide net first\n",
    "        var candidates = await RetrieveCandidatesAsync(queryVector, limit: 25);\n",
    "        var lambda = GetOptimalLambda(question, domain);\n",
    "        var selectedDocs = MaximumMarginalRelevance.ComputeMMR(\n",
    "            vectors: candidates.Select(c => c.Embedding).ToList(),\n",
    "            query: queryVector,\n",
    "            lambda: lambda,\n",
    "            topK: 5\n",
    "        );\n",
    "        \n",
    "        var selectedCandidates = selectedDocs.Select(doc => candidates[doc.index]).ToList();\n",
    "        _logger.LogInformation(\"Selected {SelectedCount} documents using MMR (λ={Lambda}) for {RequestId}\", \n",
    "            selectedCandidates.Count, lambda, requestId);\n",
    "        \n",
    "        // 5. Build response\n",
    "        var response = new RAGResponse\n",
    "        {\n",
    "            RequestId = requestId,\n",
    "            Answer = GenerateAnswer(question, selectedCandidates),\n",
    "            SourceDocuments = selectedCandidates,\n",
    "            Lambda = lambda,\n",
    "            Domain = domain,\n",
    "            FromCache = false\n",
    "        };\n",
    "        \n",
    "        // 6. Cache for future requests\n",
    "        _cache.Set(cacheKey, response, TimeSpan.FromMinutes(15));\n",
    "        \n",
    "        return response;\n",
    "    }\n",
    "    \n",
    "    // Adaptive lambda selection based on query characteristics\n",
    "    private double GetOptimalLambda(string question, string domain)\n",
    "    {\n",
    "        var questionLower = question.ToLowerInvariant();\n",
    "        \n",
    "        // Query-based selection\n",
    "        if (questionLower.Contains(\"how to\") || questionLower.Contains(\"steps\"))\n",
    "            return 0.8; // Precision for procedures\n",
    "            \n",
    "        if (questionLower.Contains(\"compare\") || questionLower.Contains(\"different\"))\n",
    "            return 0.5; // Diversity for comparisons\n",
    "            \n",
    "        // Domain-based defaults\n",
    "        return domain.ToLowerInvariant() switch\n",
    "        {\n",
    "            \"support\" => 0.8,\n",
    "            \"research\" => 0.6,\n",
    "            \"legal\" => 0.9,\n",
    "            \"technical\" => 0.75,\n",
    "            _ => 0.7\n",
    "        };\n",
    "    }\n",
    "    \n",
    "    private async Task<List<DocumentCandidate>> RetrieveCandidatesAsync(Vector<double> queryEmbedding, int limit)\n",
    "    {\n",
    "        return _documents\n",
    "            .Select(doc => new DocumentCandidate\n",
    "            {\n",
    "                Id = doc.Id,\n",
    "                Title = doc.Title,\n",
    "                Content = doc.Content,\n",
    "                Embedding = doc.Embedding,\n",
    "                Score = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), doc.Embedding.ToArray())\n",
    "            })\n",
    "            .OrderByDescending(d => d.Score)\n",
    "            .Take(limit)\n",
    "            .ToList();\n",
    "    }\n",
    "    \n",
    "    private string GenerateAnswer(string question, List<DocumentCandidate> documents)\n",
    "    {\n",
    "        return $\"Based on {documents.Count} diverse sources selected using MMR, here's the answer to '{question}': \" +\n",
    "               $\"[This would be generated by your LLM using the selected context. The MMR algorithm ensured \" +\n",
    "               $\"we have diverse, relevant information rather than repetitive similar documents.]\"; \n",
    "    }\n",
    "    \n",
    "    private List<DocumentCandidate> GenerateDocumentDatabase()\n",
    "    {\n",
    "        // Generate a diverse set of mock documents for demonstration\n",
    "        var documents = new List<DocumentCandidate>();\n",
    "        var random = new Random(42);\n",
    "        \n",
    "        var sampleContent = new[]\n",
    "        {\n",
    "            \"API authentication requires OAuth 2.0 tokens for secure access to endpoints.\",\n",
    "            \"Password reset instructions: Click 'Forgot Password' and follow email instructions.\",\n",
    "            \"Data privacy regulations require explicit consent for personal information collection.\",\n",
    "            \"System performance can be optimized through proper caching strategies.\",\n",
    "            \"Database indexing improves query performance significantly.\",\n",
    "            \"Load balancing distributes traffic across multiple servers.\",\n",
    "            \"Error handling should provide meaningful messages to users.\",\n",
    "            \"Code reviews help maintain quality and share knowledge.\",\n",
    "            \"Automated testing reduces bugs in production deployments.\",\n",
    "            \"Documentation should be kept up-to-date with code changes.\"\n",
    "        };\n",
    "        \n",
    "        for (int i = 0; i < 30; i++)\n",
    "        {\n",
    "            var content = sampleContent[i % sampleContent.Length];\n",
    "            documents.Add(new DocumentCandidate\n",
    "            {\n",
    "                Id = $\"doc_{i:D3}\",\n",
    "                Title = $\"Document {i}: Technical Information\",\n",
    "                Content = content,\n",
    "                Embedding = Vector<double>.Build.Dense(384, j => random.NextDouble() - 0.5).Normalize(2)\n",
    "            });\n",
    "        }\n",
    "        \n",
    "        return documents;\n",
    "    }\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"✅ Production RAG service implementation complete!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production RAG Service Demo\n",
    "\n",
    "Let's test the production service with different scenarios to see adaptive lambda selection and two-stage retrieval in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Create and test the production RAG service\n",
    "// Set up dependency injection services\n",
    "var services = new ServiceCollection()\n",
    "    .AddMemoryCache()\n",
    "    .AddLogging(builder => builder.AddConsole())\n",
    "    .BuildServiceProvider();\n",
    "\n",
    "var cache = services.GetRequiredService<IMemoryCache>();\n",
    "var logger = services.GetRequiredService<ILogger<ProductionRAGService>>();\n",
    "var ragService = new ProductionRAGService(embeddingGenerator, cache, logger);\n",
    "\n",
    "Console.WriteLine(\"🚀 PRODUCTION RAG SERVICE DEMONSTRATION\");\n",
    "Console.WriteLine(\"Testing adaptive lambda selection and two-stage retrieval:\\n\");\n",
    "\n",
    "// Test different query types to see adaptive lambda selection\n",
    "var testQueries = new[]\n",
    "{\n",
    "    (\"How to deploy a web application?\", \"technical\", \"Procedural query - should use high lambda\"),\n",
    "    (\"Compare different authentication methods\", \"research\", \"Comparative query - should use balanced lambda\"),\n",
    "    (\"My password reset isn't working\", \"support\", \"Support query - should use high precision lambda\"),\n",
    "    (\"What are the latest trends in AI?\", \"general\", \"General query - should use default lambda\")\n",
    "};\n",
    "\n",
    "foreach (var (question, domain, description) in testQueries)\n",
    "{\n",
    "    Console.WriteLine($\"🎯 {description}\");\n",
    "    Console.WriteLine($\"Query: \\\"{question}\\\" (domain: {domain})\");\n",
    "    \n",
    "    var response = await ragService.AskQuestionAsync(question, domain);\n",
    "    \n",
    "    Console.WriteLine($\"✅ Lambda used: {response.Lambda:F2}\");\n",
    "    Console.WriteLine($\"📄 Documents selected: {response.SourceDocuments.Count}\");\n",
    "    Console.WriteLine($\"💾 From cache: {response.FromCache}\");\n",
    "    Console.WriteLine($\"📝 Answer preview: {response.Answer[..Math.Min(100, response.Answer.Length)]}...\");\n",
    "    Console.WriteLine();\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"✅ Production RAG service demonstration complete!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Stage Retrieval Pattern\n",
    "\n",
    "This pattern is essential for scalable RAG systems:\n",
    "\n",
    "**Why Two-Stage Retrieval:**\n",
    "- **Computational Efficiency**: O(n) initial retrieval + O(k²) MMR vs O(n²) naive MMR\n",
    "- **Memory Optimization**: Process subset in memory rather than entire corpus\n",
    "- **Latency Control**: Sub-second response times with millions of documents\n",
    "\n",
    "**Implementation:**\n",
    "1. **Stage 1**: Efficient vector similarity search (25-50 candidates)\n",
    "2. **Stage 2**: MMR diversity selection (5-10 final documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Demonstrate two-stage retrieval pattern\n",
    "Console.WriteLine(\"🔄 TWO-STAGE RETRIEVAL PATTERN DEMONSTRATION\");\n",
    "Console.WriteLine(\"This is the pattern used in production RAG systems:\\n\");\n",
    "\n",
    "var demoQuery = \"API security best practices\";\n",
    "var demoQueryEmbedding = await embeddingGenerator.GenerateVectorAsync(demoQuery);\n",
    "\n",
    "// Simulate a larger document database\n",
    "var largeDocumentSet = new List<DocumentCandidate>();\n",
    "var random = new Random(42);\n",
    "var topics = new[] { \"API Security\", \"Authentication\", \"Authorization\", \"Data Privacy\", \"Performance\", \"Monitoring\", \"Testing\", \"Documentation\" };\n",
    "\n",
    "for (int i = 0; i < 100; i++)\n",
    "{\n",
    "    var topic = topics[i % topics.Length];\n",
    "    largeDocumentSet.Add(new DocumentCandidate\n",
    "    {\n",
    "        Id = $\"large_doc_{i:D3}\",\n",
    "        Title = $\"{topic} Guide {i}\",\n",
    "        Content = $\"This document covers {topic.ToLower()} concepts and best practices for enterprise applications.\",\n",
    "        Embedding = Vector<double>.Build.Dense(384, j => random.NextDouble() - 0.5).Normalize(2)\n",
    "    });\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"📊 Total documents in database: {largeDocumentSet.Count}\");\n",
    "Console.WriteLine($\"🔍 Query: \\\"{demoQuery}\\\"\");\n",
    "\n",
    "// Stage 1: Broad retrieval\n",
    "Console.WriteLine(\"\\n📋 STAGE 1: Broad Candidate Retrieval\");\n",
    "var demoQueryVector = demoQueryEmbedding.ToArray().Select(f => (double)f).ToArray();\n",
    "var broadCandidates = largeDocumentSet\n",
    "    .Select(doc => new DocumentCandidate\n",
    "    {\n",
    "        Id = doc.Id,\n",
    "        Title = doc.Title,\n",
    "        Content = doc.Content,\n",
    "        Embedding = doc.Embedding,\n",
    "        Score = 1.0 - Distance.Cosine(demoQueryVector, doc.Embedding.ToArray())\n",
    "    })\n",
    "    .OrderByDescending(d => d.Score)\n",
    "    .Take(25)\n",
    "    .ToList();\n",
    "\n",
    "Console.WriteLine($\"✅ Retrieved {broadCandidates.Count} candidates from {largeDocumentSet.Count} total documents\");\n",
    "Console.WriteLine($\"📈 Top candidate similarity: {broadCandidates.First().Score:F3}\");\n",
    "Console.WriteLine($\"📉 Lowest candidate similarity: {broadCandidates.Last().Score:F3}\");\n",
    "\n",
    "// Stage 2: MMR selection\n",
    "var demoQueryVectorForMMR = Vector<double>.Build.DenseOfArray(demoQueryVector);\n",
    "var mmrSelected = MaximumMarginalRelevance.ComputeMMR(\n",
    "    vectors: broadCandidates.Select(c => c.Embedding).ToList(),\n",
    "    query: demoQueryVectorForMMR,\n",
    "    lambda: 0.7,\n",
    "    topK: 5\n",
    ");\n",
    "\n",
    "var finalDocuments = mmrSelected.Select(doc => broadCandidates[doc.index]).ToList();\n",
    "\n",
    "Console.WriteLine($\"✅ Selected {finalDocuments.Count} diverse documents using MMR (λ=0.7)\");\n",
    "Console.WriteLine(\"\\n📚 Final Selected Documents:\");\n",
    "foreach (var doc in finalDocuments)\n",
    "{\n",
    "    Console.WriteLine($\"   • {doc.Title} (similarity: {doc.Score:F3})\");\n",
    "}\n",
    "\n",
    "// Show topic diversity\n",
    "var selectedTopics = finalDocuments.Select(d => d.Title.Split(' ')[0]).Distinct().Count();\n",
    "Console.WriteLine($\"\\n🎯 Topic diversity: {selectedTopics} different topics covered\");\n",
    "Console.WriteLine(\"\\n💡 This two-stage approach scales to millions of documents while maintaining MMR benefits!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights and Best Practices\n",
    "\n",
    "### MMR Advantages\n",
    "- **Solves Clustering Problem**: Prevents repetitive, similar results\n",
    "- **Improves User Experience**: Provides comprehensive, diverse information\n",
    "- **Reduces Follow-up Questions**: Users get complete answers upfront\n",
    "\n",
    "### Lambda Selection Strategy\n",
    "- **λ = 0.8-0.9**: High precision domains (support, legal, medical)\n",
    "- **λ = 0.7**: General-purpose applications (recommended starting point)\n",
    "- **λ = 0.5-0.6**: Research and comparative analysis\n",
    "- **λ = 0.3-0.4**: Content discovery and exploration\n",
    "\n",
    "### Production Patterns\n",
    "- **Two-Stage Retrieval**: Essential for scalability\n",
    "- **Adaptive Lambda**: Query and domain-based selection\n",
    "- **Intelligent Caching**: Improves performance significantly\n",
    "- **Comprehensive Logging**: Critical for monitoring and optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Applications\n",
    "\n",
    "MMR improves many AI applications beyond traditional RAG:\n",
    "\n",
    "### E-commerce Recommendations\n",
    "Instead of 10 similar smartphones, users get phones, cases, chargers, and accessories.\n",
    "\n",
    "### Content Curation\n",
    "A tech newsletter about \"AI developments\" covers language models, computer vision, robotics, ethics, and applications instead of 5 ChatGPT articles.\n",
    "\n",
    "### Customer Support\n",
    "Support tickets get diverse solution approaches: basic fixes, system compatibility, and escalation paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Ready to implement MMR in your RAG system?\n",
    "\n",
    "### 1. Start Simple\n",
    "- Begin with λ = 0.7 for general use\n",
    "- Replace one retrieval call initially\n",
    "- Measure before expanding\n",
    "\n",
    "### 2. Integrate MEAI\n",
    "- Replace mock embeddings with Azure OpenAI\n",
    "- Use `text-embedding-3-small` for production\n",
    "- Implement proper error handling and retries\n",
    "\n",
    "### 3. Add Production Features\n",
    "- Implement two-stage retrieval pattern\n",
    "- Add adaptive lambda selection\n",
    "- Set up caching and monitoring\n",
    "\n",
    "### 4. Monitor and Optimize\n",
    "- Track user satisfaction and task completion\n",
    "- Monitor topic diversity in responses\n",
    "- A/B test different lambda values\n",
    "- Measure follow-up question rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've learned how Maximum Marginal Relevance transforms RAG systems by balancing relevance with diversity.\n",
    "\n",
    "### What You've Accomplished\n",
    "- ✅ **Understood the Problem**: Identified why traditional RAG falls short\n",
    "- ✅ **Learned MMR Theory**: Mastered the relevance-diversity balance\n",
    "- ✅ **Implemented with MEAI**: Built production-ready integration\n",
    "- ✅ **Explored Real Examples**: Saw MMR solve actual clustering problems\n",
    "- ✅ **Mastered Lambda Tuning**: Learned when to use different values\n",
    "- ✅ **Built Production Patterns**: Implemented scalable, enterprise-ready solutions\n",
    "\n",
    "### The Impact\n",
    "With MMR integration, your RAG system:\n",
    "- **Avoids Information Clustering**: Diverse perspectives in every response\n",
    "- **Adapts to Use Cases**: Different domains get optimized behavior\n",
    "- **Scales with Demand**: Production patterns support growth\n",
    "- **Provides Insights**: Comprehensive observability enables optimization\n",
    "\n",
    "**Start with λ = 0.7 and watch your users get the comprehensive, diverse answers they deserve!** 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
