{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond Basic RAG: How Maximum Marginal Relevance Transforms Your .NET Applications\n",
    "\n",
    "*Taking RAG systems from good to great with intelligent context selection*\n",
    "\n",
    "---\n",
    "\n",
    "Your AI assistant just told a user to \"restart the service\" three times in a row, using slightly different words each time. Meanwhile, the specific configuration changes they actually needed never made it into the response.\n",
    "\n",
    "If you've built a RAG system, you've seen this. Your vector search finds the most relevant documents, but they all say the same thing. You get repetitive information instead of comprehensive answers.\n",
    "\n",
    "This notebook demonstrates **Maximum Marginal Relevance (MMR)** - a technique that solves this problem by balancing relevance with diversity. We'll see why it matters and how to implement it in .NET with **Microsoft.Extensions.AI** integration.\n",
    "\n",
    "## What You'll Learn üéØ\n",
    "\n",
    "- **The Context Selection Problem**: Why traditional RAG falls short\n",
    "- **MMR Theory & Practice**: Balancing relevance with diversity\n",
    "- **MEAI Integration**: Using Microsoft.Extensions.AI with Azure OpenAI\n",
    "- **Real-World Examples**: E-commerce, customer support, and more\n",
    "- **Production Patterns**: Two-stage retrieval and adaptive lambda selection\n",
    "- **Interactive Exploration**: Hands-on parameter tuning\n",
    "\n",
    "Let's transform your RAG system from good to great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration üì¶\n",
    "\n",
    "First, let's install the necessary packages and set up our environment with Microsoft.Extensions.AI integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>AiGeekSquad.AIContext, 1.0.35</span></li><li><span>AiGeekSquad.AIContext.MEAI, 1.0.35</span></li><li><span>MathNet.Numerics, 5.0.0</span></li><li><span>Microsoft.Extensions.AI, 9.7.1</span></li><li><span>microsoft.extensions.ai.abstractions, 9.7.1</span></li><li><span>Microsoft.Extensions.Caching.Memory, 10.0.0-preview.6.25358.103</span></li><li><span>Microsoft.Extensions.Configuration, 10.0.0-preview.6.25358.103</span></li><li><span>Microsoft.Extensions.DependencyInjection, 10.0.0-preview.6.25358.103</span></li><li><span>Microsoft.Extensions.Logging, 10.0.0-preview.6.25358.103</span></li><li><span>Microsoft.Extensions.Logging.Console, 10.0.0-preview.6.25358.103</span></li><li><span>OllamaSharp, 5.3.4</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Packages loaded successfully!\n",
      "üì¶ MathNet.Numerics: 5.0.0.0\n"
     ]
    }
   ],
   "source": [
    "// Install required NuGet packages\n",
    "#r \"nuget: MathNet.Numerics, 5.0.0\"\n",
    "#r \"nuget: AiGeekSquad.AIContext, *-*\"\n",
    "#r \"nuget: AiGeekSquad.AIContext.MEAI, *-*\"\n",
    "#r \"nuget: OllamaSharp, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.AI.Abstractions, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.AI, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.DependencyInjection, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Logging, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Logging.Console, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration, *-*\"\n",
    "#r \"nuget: Microsoft.Extensions.Caching.Memory, *-*\"\n",
    "\n",
    "using System;\n",
    "using OllamaSharp;\n",
    "using System.Collections.Generic;\n",
    "using System.Linq;\n",
    "using System.Threading;\n",
    "using System.Threading.Tasks;\n",
    "using Microsoft.Extensions.AI;\n",
    "using Microsoft.Extensions.DependencyInjection;\n",
    "using Microsoft.Extensions.Logging;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using Microsoft.Extensions.Caching.Memory;\n",
    "using MathNet.Numerics.LinearAlgebra;\n",
    "using MathNet.Numerics;\n",
    "using AiGeekSquad.AIContext.Ranking;\n",
    "using AiGeekSquad.AIContext.Chunking;\n",
    "using AiGeekSquad.AIContext.MEAI;\n",
    "using IEmbeddingGenerator = Microsoft.Extensions.AI.IEmbeddingGenerator;\n",
    "\n",
    "Console.WriteLine(\"‚úÖ Packages loaded successfully!\");\n",
    "Console.WriteLine($\"üì¶ MathNet.Numerics: {typeof(MathNet.Numerics.Control).Assembly.GetName().Version}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEAI Service Configuration\n",
    "\n",
    "Let's set up Microsoft.Extensions.AI with Azure OpenAI integration and a fallback to mock embeddings for offline demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "IEmbeddingGenerator<string,Embedding<float>> embeddingGenerator = \n",
    "    new OllamaApiClient(\"http://localhost:11434\", \"all-minilm\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Context Selection Problem üéØ\n",
    "\n",
    "RAG systems face a fundamental constraint: language models have limited context windows. You need to be selective about which documents you include.\n",
    "\n",
    "When you can only include a few documents, each one needs to add unique value. If three of your five documents say the same thing, you're wasting 60% of your context space.\n",
    "\n",
    "### What Goes Wrong\n",
    "\n",
    "Poor context selection creates several problems:\n",
    "\n",
    "- Generic answers instead of specific solutions\n",
    "- Important information gets left out  \n",
    "- Users receive contradictory advice\n",
    "- Higher follow-up question rates\n",
    "- Reduced user trust\n",
    "\n",
    "**Real examples:**\n",
    "- Medical system mixing Type 1 and Type 2 diabetes information\n",
    "- Legal system combining precedents from different jurisdictions  \n",
    "- Support system showing upgrade info when someone wants to cancel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Semantic Search Falls Short üîç\n",
    "\n",
    "Traditional RAG uses semantic search to find the most relevant documents. This creates a clustering problem: highly similar documents often cluster around the same topics.\n",
    "\n",
    "Query: \"optimizing application performance\"  \n",
    "Results: Three documents about memory management, nothing about databases or caching.\n",
    "\n",
    "Here's the problem in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'wireless headphones'\n",
      "\n",
      "Traditional search (top 3 most similar):\n",
      "‚Ä¢ Sony WH-1000XM4 Wireless Headphones (similarity: 0.95)\n",
      "‚Ä¢ Bose QuietComfort Wireless Headphones (similarity: 0.93)\n",
      "‚Ä¢ Apple AirPods Pro Wireless Earbuds (similarity: 0.91)\n",
      "\n",
      "Problem: Only 1 category represented - missing accessories!\n",
      "Traditional search returns three similar headphones but misses complementary accessories customers often need.\n"
     ]
    }
   ],
   "source": [
    "// E-commerce search demonstrating the clustering problem\n",
    "var products = new[]\n",
    "{\n",
    "    new { Name = \"Sony WH-1000XM4 Wireless Headphones\", Similarity = 0.95, Category = \"Audio\" },\n",
    "    new { Name = \"Bose QuietComfort Wireless Headphones\", Similarity = 0.93, Category = \"Audio\" },\n",
    "    new { Name = \"Apple AirPods Pro Wireless Earbuds\", Similarity = 0.91, Category = \"Audio\" },\n",
    "    new { Name = \"Wireless Phone Charger\", Similarity = 0.45, Category = \"Accessories\" },\n",
    "    new { Name = \"Bluetooth Speaker\", Similarity = 0.42, Category = \"Audio\" },\n",
    "    new { Name = \"USB-C Cable\", Similarity = 0.15, Category = \"Accessories\" }\n",
    "};\n",
    "\n",
    "Console.WriteLine(\"Query: 'wireless headphones'\");\n",
    "Console.WriteLine(\"\\nTraditional search (top 3 most similar):\");\n",
    "\n",
    "var traditionalResults = products\n",
    "    .OrderByDescending(p => p.Similarity)\n",
    "    .Take(3);\n",
    "    \n",
    "foreach (var product in traditionalResults)\n",
    "{\n",
    "    Console.WriteLine($\"‚Ä¢ {product.Name} (similarity: {product.Similarity})\");\n",
    "}\n",
    "\n",
    "var uniqueCategories = traditionalResults.Select(p => p.Category).Distinct().Count();\n",
    "Console.WriteLine($\"\\nProblem: Only {uniqueCategories} category represented - missing accessories!\");\n",
    "Console.WriteLine(\"Traditional search returns three similar headphones but misses complementary accessories customers often need.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Marginal Relevance Explained ‚öñÔ∏è\n",
    "\n",
    "MMR balances two goals:\n",
    "1. **Relevance** - How well does a document match your query?\n",
    "2. **Diversity** - How different is it from documents you've already selected?\n",
    "\n",
    "### The Formula\n",
    "\n",
    "```\n",
    "MMR Score = Œª √ó Relevance + (1-Œª) √ó Diversity\n",
    "```\n",
    "\n",
    "- **Relevance** is how well a document matches your query. \n",
    "- **Diversity** is how different it is from documents you've already selected.\n",
    "\n",
    "Think of it like preparing for a meeting: you want data that's relevant to your proposal, but you don't want five charts showing the same sales trend. You want the key metrics plus supporting insights from different angles that help stakeholders understand the complete picture.\n",
    "\n",
    "The `Œª` (lambda) parameter controls the balance:\n",
    "\n",
    "- **Œª = 1.0**: Pure relevance (traditional search) - gives you the most similar results\n",
    "- **Œª = 0.7**: Mostly relevance with some variety (good starting point) - covers your main topic plus related information\n",
    "- **Œª = 0.5**: Equal balance - broader coverage of the problem space\n",
    "- **Œª = 0.0**: Pure diversity - maximum variety, but might miss your actual question\n",
    "\n",
    "**Example:** Query \"API authentication issues\"\n",
    "- Œª = 1.0: Three documents about JWT validation (repetitive)\n",
    "- Œª = 0.7: JWT validation, OAuth setup, API key management (comprehensive)\n",
    "\n",
    "Start with Œª = 0.7 for most applications. This prevents the \"echo chamber\" effect where all results say the same thing, while still answering your specific question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with MEAI üõ†Ô∏è\n",
    "\n",
    "Let's implement MMR with Microsoft.Extensions.AI integration, showing how it solves the clustering problem in real scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating embeddings using MEAI...\n",
      "‚úÖ Generated embeddings for 6 solutions\n",
      "üìä Embedding dimensions: 384\n",
      "\n",
      "=== Support Ticket: 'App won't start' ===\n",
      "\n",
      "üîç BEFORE - Traditional Search (top 3):\n",
      "‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565)\n",
      "‚Ä¢ Reinstall the app to fix corrupted installation (similarity: 0.530)\n",
      "‚Ä¢ Restart the application to fix temporary glitches (similarity: 0.496)\n",
      "\n",
      "‚ú® AFTER - MMR Search (Œª = 0.7):\n",
      "‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565, MMR score: DenseVector 384-Double\n",
      " 0.039  -0.026   0.053  -0.029   0.012   0.064   0.015  -0.046   0.067  -0.132\n",
      " 0.033   0.021   0.019  -0.040  -0.020  -0.020  -0.024   0.025  -0.024   0.033\n",
      " 0.025   0.017   0.019  -0.035   0.044   0.019  -0.121   0.068  -0.046  -0.012\n",
      "-0.056   0.065  -0.036  -0.005   0.020   0.018   0.018  -0.052   0.043  -0.027\n",
      "-0.018   0.027   0.015   0.081  -0.018   0.069  -0.002   0.046   0.046  -0.016\n",
      "-0.057  -0.036   0.005   0.028  -0.069   0.027  -0.025  -0.006   0.025   0.041\n",
      " 0.017  -0.027  -0.001  -0.071   0.023  -0.003  -0.030   0.036   0.020   0.066\n",
      " 0.023   0.032   0.006   0.103   0.032  -0.075  -0.082   0.000   0.091  -0.042\n",
      "-0.029  -0.061  -0.032   0.033  -0.009   0.058   0.004   0.058   0.024  -0.023\n",
      " 0.038   0.037  -0.019   0.021   0.059  -0.028  -0.028   0.021   0.019   0.011\n",
      " 0.014  -0.004   0.048   0.057   0.006  -0.040  -0.030  -0.028   0.026      ..\n",
      " 0.065   0.095   0.084   0.040   0.078   0.085   0.095  -0.006  -0.009  -0.090\n",
      ")\n",
      "‚Ä¢ Reinstall the app to fix corrupted installation (similarity: 0.530, MMR score: DenseVector 384-Double\n",
      "-0.009   0.019   0.049   0.014   0.063   0.076   0.016   0.051   0.070  -0.027\n",
      "-0.017   0.034  -0.020  -0.072   0.031   0.066  -0.037  -0.008  -0.013  -0.038\n",
      " 0.067  -0.031  -0.086  -0.026   0.000   0.005  -0.121   0.023  -0.071  -0.022\n",
      "-0.087   0.026   0.049  -0.019   0.033   0.063  -0.024  -0.074   0.070  -0.062\n",
      "-0.045   0.037   0.012   0.022   0.020   0.010  -0.030   0.064  -0.007   0.006\n",
      "-0.071   0.066  -0.023   0.053   0.015   0.071  -0.005   0.030  -0.101   0.003\n",
      " 0.009   0.025  -0.013  -0.058   0.044  -0.054  -0.105  -0.003  -0.019   0.077\n",
      " 0.016   0.036  -0.010   0.028   0.066  -0.114  -0.000   0.014  -0.054   0.006\n",
      "-0.037  -0.075   0.016   0.024  -0.012   0.062   0.001   0.092   0.000  -0.072\n",
      "-0.016   0.082  -0.024  -0.009   0.114  -0.037  -0.011  -0.031  -0.043   0.017\n",
      " 0.059  -0.035   0.056   0.064   0.035  -0.035  -0.035   0.021  -0.021      ..\n",
      " 0.037   0.006  -0.006   0.053   0.074   0.010   0.061   0.015  -0.001  -0.022\n",
      ")\n",
      "‚Ä¢ Restart the application to fix temporary glitches (similarity: 0.496, MMR score: DenseVector 384-Double\n",
      " 0.005  -0.023  -0.034  -0.049   0.022   0.052  -0.036   0.139   0.058  -0.035\n",
      "-0.065  -0.009   0.004  -0.021   0.021   0.072  -0.052  -0.012  -0.034  -0.047\n",
      " 0.050   0.003  -0.007  -0.004   0.047  -0.002  -0.038   0.058  -0.068  -0.035\n",
      "-0.027   0.003  -0.034  -0.023   0.018  -0.009   0.049  -0.055   0.085  -0.007\n",
      "-0.061  -0.027   0.014  -0.040   0.026   0.027  -0.097   0.126   0.006   0.049\n",
      "-0.048   0.046  -0.023   0.022  -0.019   0.085  -0.057   0.060  -0.108  -0.007\n",
      "-0.008  -0.037  -0.048  -0.080   0.066   0.007  -0.014  -0.010   0.089   0.026\n",
      " 0.048   0.006   0.063   0.032   0.048  -0.102  -0.011  -0.014   0.046   0.012\n",
      "-0.079  -0.057  -0.054   0.037   0.058   0.019   0.124   0.036   0.053  -0.067\n",
      "-0.004  -0.010   0.001  -0.025   0.067  -0.021  -0.035   0.007   0.034   0.010\n",
      " 0.029  -0.084   0.087   0.077   0.008   0.019  -0.019  -0.057   0.031      ..\n",
      " 0.027   0.018   0.103   0.022   0.118   0.044   0.074  -0.032   0.086  -0.005\n",
      ")\n",
      "\n",
      "‚úÖ MMR provides diverse troubleshooting approaches instead of repetitive similar solutions!\n"
     ]
    }
   ],
   "source": [
    "// Customer support: \"app crashes on startup\"\n",
    "// This example demonstrates MMR solving a customer support scenario\n",
    "\n",
    "// Generate embeddings for solution categories using MEAI\n",
    "var solutionTexts = new[]\n",
    "{\n",
    "    \"Clear app cache and data to resolve startup issues\",\n",
    "    \"Restart the application to fix temporary glitches\", \n",
    "    \"Reinstall the app to fix corrupted installation\",\n",
    "    \"Check system requirements and compatibility\",\n",
    "    \"Update device drivers for hardware compatibility\",\n",
    "    \"Contact technical support for advanced troubleshooting\"\n",
    "};\n",
    "\n",
    "Console.WriteLine(\"üîÑ Generating embeddings using MEAI...\");\n",
    "\n",
    "// Generate embeddings for all solutions\n",
    "var solutionEmbeddings = new List<(string solution, Vector<double> embedding)>();\n",
    "foreach (var solution in solutionTexts)\n",
    "{\n",
    "    var embeddingResult = await embeddingGenerator.GenerateVectorAsync(solution);\n",
    "    var embedding = Vector<double>.Build.DenseOfArray(embeddingResult.ToArray().Select(f => (double)f).ToArray());\n",
    "    solutionEmbeddings.Add((solution, embedding));\n",
    "}\n",
    "\n",
    "// Generate query embedding\n",
    "var queryText = \"app crashes on startup\";\n",
    "var queryEmbeddingResult = await embeddingGenerator.GenerateVectorAsync(queryText);\n",
    "var queryEmbedding = Vector<double>.Build.DenseOfArray(queryEmbeddingResult.ToArray().Select(f => (double)f).ToArray());\n",
    "\n",
    "Console.WriteLine($\"‚úÖ Generated embeddings for {solutionEmbeddings.Count} solutions\");\n",
    "Console.WriteLine($\"üìä Embedding dimensions: {queryEmbedding.Count}\");\n",
    "\n",
    "Console.WriteLine(\"\\n=== Support Ticket: 'App won't start' ===\");\n",
    "\n",
    "// Traditional search (most similar)\n",
    "Console.WriteLine(\"\\nüîç BEFORE - Traditional Search (top 3):\");\n",
    "var traditionalSupport = solutionEmbeddings\n",
    "    .Select((sol, idx) => new { \n",
    "        Index = idx, \n",
    "        Solution = sol.solution, \n",
    "        Similarity = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), sol.embedding.ToArray()) \n",
    "    })\n",
    "    .OrderByDescending(x => x.Similarity)\n",
    "    .Take(3);\n",
    "\n",
    "foreach (var result in traditionalSupport)\n",
    "{\n",
    "    Console.WriteLine($\"‚Ä¢ {result.Solution} (similarity: {result.Similarity:F3})\");\n",
    "}\n",
    "\n",
    "// MMR search (balanced relevance and diversity)\n",
    "Console.WriteLine(\"\\n‚ú® AFTER - MMR Search (Œª = 0.7):\");\n",
    "var mmrResults = MaximumMarginalRelevance.ComputeMMR(\n",
    "    vectors: solutionEmbeddings.Select(s => s.embedding).ToList(),\n",
    "    query: queryEmbedding,\n",
    "    lambda: 0.7,\n",
    "    topK: 3\n",
    ");\n",
    "\n",
    "foreach (var (index, score) in mmrResults)\n",
    "{\n",
    "    var solution = solutionEmbeddings[index].solution;\n",
    "    var similarity = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), solutionEmbeddings[index].embedding.ToArray());\n",
    "    Console.WriteLine($\"‚Ä¢ {solution} (similarity: {similarity:F3}, MMR score: {score:F3})\");\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"\\n‚úÖ MMR provides diverse troubleshooting approaches instead of repetitive similar solutions!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Lambda Values üéõÔ∏è\n",
    "\n",
    "The lambda parameter is crucial for getting the right balance. Let's explore how different values affect results and learn when to use each approach.\n",
    "\n",
    "| Lambda | Balance | Best For |\n",
    "|:------:|:--------|:---------|\n",
    "| **0.9** | High relevance | FAQ systems, troubleshooting |\n",
    "| **0.7** | Balanced (recommended) | General-purpose RAG |\n",
    "| **0.5** | Equal balance | Research, comparative analysis |\n",
    "| **0.3** | High diversity | Content discovery, brainstorming |\n",
    "\n",
    "**Domain recommendations:**\n",
    "- Customer Support: Œª = 0.8 (accuracy matters)\n",
    "- Research Tools: Œª = 0.6 (diverse perspectives help)\n",
    "- Content Discovery: Œª = 0.4 (exploration focus)\n",
    "- Technical Docs: Œª = 0.8 (precision critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéõÔ∏è LAMBDA PARAMETER EXPLORATION\n",
      "Let's see how different lambda values affect our support ticket results:\n",
      "\n",
      "üéØ Lambda = 1 (Pure Relevance - Traditional Search):\n",
      "   ‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565)\n",
      "   ‚Ä¢ Reinstall the app to fix corrupted installation (similarity: 0.530)\n",
      "   ‚Ä¢ Restart the application to fix temporary glitches (similarity: 0.496)\n",
      "   üìä Solution categories covered: 1 (basic_fixes)\n",
      "\n",
      "üéØ Lambda = 0.8 (High Relevance - Customer Support Recommended):\n",
      "   ‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565)\n",
      "   ‚Ä¢ Reinstall the app to fix corrupted installation (similarity: 0.530)\n",
      "   ‚Ä¢ Restart the application to fix temporary glitches (similarity: 0.496)\n",
      "   üìä Solution categories covered: 1 (basic_fixes)\n",
      "\n",
      "üéØ Lambda = 0.7 (Balanced - General Purpose):\n",
      "   ‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565)\n",
      "   ‚Ä¢ Reinstall the app to fix corrupted installation (similarity: 0.530)\n",
      "   ‚Ä¢ Restart the application to fix temporary glitches (similarity: 0.496)\n",
      "   üìä Solution categories covered: 1 (basic_fixes)\n",
      "\n",
      "üéØ Lambda = 0.5 (Equal Balance - Research/Analysis):\n",
      "   ‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565)\n",
      "   ‚Ä¢ Check system requirements and compatibility (similarity: 0.083)\n",
      "   ‚Ä¢ Restart the application to fix temporary glitches (similarity: 0.496)\n",
      "   üìä Solution categories covered: 2 (basic_fixes, system_issues)\n",
      "\n",
      "üéØ Lambda = 0.3 (High Diversity - Content Discovery):\n",
      "   ‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565)\n",
      "   ‚Ä¢ Check system requirements and compatibility (similarity: 0.083)\n",
      "   ‚Ä¢ Restart the application to fix temporary glitches (similarity: 0.496)\n",
      "   üìä Solution categories covered: 2 (basic_fixes, system_issues)\n",
      "\n",
      "üéØ Lambda = 0 (Pure Diversity - Maximum Variety):\n",
      "   ‚Ä¢ Clear app cache and data to resolve startup issues (similarity: 0.565)\n",
      "   ‚Ä¢ Check system requirements and compatibility (similarity: 0.083)\n",
      "   ‚Ä¢ Contact technical support for advanced troubleshooting (similarity: 0.201)\n",
      "   üìä Solution categories covered: 3 (basic_fixes, system_issues, escalation)\n",
      "\n",
      "üí° Key Insight: Higher lambda values focus on relevance, lower values increase diversity.\n",
      "   For most applications, Œª = 0.7 provides the best balance!\n"
     ]
    }
   ],
   "source": [
    "// Interactive lambda exploration\n",
    "// Let's see how different lambda values affect the same query\n",
    "\n",
    "void TestLambdaValue(double lambda, string description)\n",
    "{\n",
    "    Console.WriteLine($\"\\nüéØ Lambda = {lambda} ({description}):\");\n",
    "    \n",
    "    var results = MaximumMarginalRelevance.ComputeMMR(\n",
    "        vectors: solutionEmbeddings.Select(s => s.embedding).ToList(),\n",
    "        query: queryEmbedding,\n",
    "        lambda: lambda,\n",
    "        topK: 3\n",
    "    );\n",
    "    \n",
    "    var categories = new HashSet<string>();\n",
    "    foreach (var (index, score) in results)\n",
    "    {\n",
    "        var solution = solutionEmbeddings[index].solution;\n",
    "        var similarity = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), solutionEmbeddings[index].embedding.ToArray());\n",
    "        Console.WriteLine($\"   ‚Ä¢ {solution} (similarity: {similarity:F3})\");\n",
    "        \n",
    "        // Categorize solutions for analysis\n",
    "        if (solution.Contains(\"cache\") || solution.Contains(\"restart\") || solution.Contains(\"reinstall\"))\n",
    "            categories.Add(\"basic_fixes\");\n",
    "        else if (solution.Contains(\"system\") || solution.Contains(\"driver\"))\n",
    "            categories.Add(\"system_issues\");\n",
    "        else if (solution.Contains(\"support\"))\n",
    "            categories.Add(\"escalation\");\n",
    "    }\n",
    "    \n",
    "    Console.WriteLine($\"   üìä Solution categories covered: {categories.Count} ({string.Join(\", \", categories)})\");\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"üéõÔ∏è LAMBDA PARAMETER EXPLORATION\");\n",
    "Console.WriteLine(\"Let's see how different lambda values affect our support ticket results:\");\n",
    "\n",
    "TestLambdaValue(1.0, \"Pure Relevance - Traditional Search\");\n",
    "TestLambdaValue(0.8, \"High Relevance - Customer Support Recommended\");\n",
    "TestLambdaValue(0.7, \"Balanced - General Purpose\");\n",
    "TestLambdaValue(0.5, \"Equal Balance - Research/Analysis\");\n",
    "TestLambdaValue(0.3, \"High Diversity - Content Discovery\");\n",
    "TestLambdaValue(0.0, \"Pure Diversity - Maximum Variety\");\n",
    "\n",
    "Console.WriteLine(\"\\nüí° Key Insight: Higher lambda values focus on relevance, lower values increase diversity.\");\n",
    "Console.WriteLine(\"   For most applications, Œª = 0.7 provides the best balance!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Patterns (Simplified) üè≠\n",
    "\n",
    "Let's implement key production patterns that make MMR practical for real applications:\n",
    "\n",
    "1. **Adaptive Lambda Selection** - Choose lambda based on query type\n",
    "2. **Two-Stage Retrieval** - Cast wide net, then apply MMR\n",
    "3. **Simple Caching** - Cache results for performance\n",
    "4. **Domain-Specific Behavior** - Different domains get different treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Supporting classes defined!\r\n"
     ]
    }
   ],
   "source": [
    "// Supporting classes for production RAG service\n",
    "public class DocumentCandidate\n",
    "{\n",
    "    public string Id { get; set; }\n",
    "    public string Title { get; set; }\n",
    "    public string Content { get; set; }\n",
    "    public Vector<double> Embedding { get; set; }\n",
    "    public double Score { get; set; }\n",
    "}\n",
    "\n",
    "public class RAGResponse\n",
    "{\n",
    "    public string RequestId { get; set; }\n",
    "    public string Answer { get; set; }\n",
    "    public List<DocumentCandidate> SourceDocuments { get; set; } = new();\n",
    "    public double Lambda { get; set; }\n",
    "    public string Domain { get; set; }\n",
    "    public bool FromCache { get; set; }\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"‚úÖ Supporting classes defined!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Production RAG service implementation complete!\r\n"
     ]
    }
   ],
   "source": [
    "// Production-ready RAG service with MMR integration\n",
    "public class ProductionRAGService\n",
    "{\n",
    "    private readonly IEmbeddingGenerator<string,Embedding<float>> _embeddingGenerator;\n",
    "    private readonly IMemoryCache _cache;\n",
    "    private readonly ILogger _logger;\n",
    "    private readonly List<DocumentCandidate> _documents;\n",
    "    \n",
    "    public ProductionRAGService(IEmbeddingGenerator<string,Embedding<float>> embeddingGenerator, IMemoryCache cache, ILogger logger)\n",
    "    {\n",
    "        _embeddingGenerator = embeddingGenerator;\n",
    "        _cache = cache;\n",
    "        _logger = logger;\n",
    "        _documents = GenerateDocumentDatabase();\n",
    "    }\n",
    "    \n",
    "    public async Task<RAGResponse> AskQuestionAsync(string question, string domain = \"general\")\n",
    "    {\n",
    "        var requestId = Guid.NewGuid().ToString(\"N\")[..8];\n",
    "        _logger.LogInformation(\"Processing question {RequestId}: {Question} (domain: {Domain})\", \n",
    "            requestId, question, domain);\n",
    "        \n",
    "        // 1. Check cache first\n",
    "        var cacheKey = $\"{domain}:{question.GetHashCode():X}\";\n",
    "        if (_cache.TryGetValue(cacheKey, out RAGResponse cachedResponse))\n",
    "        {\n",
    "            _logger.LogInformation(\"Cache hit for {RequestId}\", requestId);\n",
    "            cachedResponse.FromCache = true;\n",
    "            return cachedResponse;\n",
    "        }\n",
    "        \n",
    "        // 2. Generate query embedding\n",
    "        var queryEmbedding = await _embeddingGenerator.GenerateVectorAsync(question);\n",
    "        \n",
    "        // Convert embedding to Vector<double>\n",
    "        var queryVector = Vector<double>.Build.DenseOfArray(\n",
    "            queryEmbedding.ToArray().Select(x => (double)x).ToArray());\n",
    "        \n",
    "        // 3. Two-stage retrieval: Cast wide net first\n",
    "        var candidates = await RetrieveCandidatesAsync(queryVector, limit: 25);\n",
    "        var lambda = GetOptimalLambda(question, domain);\n",
    "        var selectedDocs = MaximumMarginalRelevance.ComputeMMR(\n",
    "            vectors: candidates.Select(c => c.Embedding).ToList(),\n",
    "            query: queryVector,\n",
    "            lambda: lambda,\n",
    "            topK: 5\n",
    "        );\n",
    "        \n",
    "        var selectedCandidates = selectedDocs.Select(doc => candidates[doc.index]).ToList();\n",
    "        _logger.LogInformation(\"Selected {SelectedCount} documents using MMR (Œª={Lambda}) for {RequestId}\", \n",
    "            selectedCandidates.Count, lambda, requestId);\n",
    "        \n",
    "        // 5. Build response\n",
    "        var response = new RAGResponse\n",
    "        {\n",
    "            RequestId = requestId,\n",
    "            Answer = GenerateAnswer(question, selectedCandidates),\n",
    "            SourceDocuments = selectedCandidates,\n",
    "            Lambda = lambda,\n",
    "            Domain = domain,\n",
    "            FromCache = false\n",
    "        };\n",
    "        \n",
    "        // 6. Cache for future requests\n",
    "        _cache.Set(cacheKey, response, TimeSpan.FromMinutes(15));\n",
    "        \n",
    "        return response;\n",
    "    }\n",
    "    \n",
    "    // Adaptive lambda selection based on query characteristics\n",
    "    private double GetOptimalLambda(string question, string domain)\n",
    "    {\n",
    "        var questionLower = question.ToLowerInvariant();\n",
    "        \n",
    "        // Query-based selection\n",
    "        if (questionLower.Contains(\"how to\") || questionLower.Contains(\"steps\"))\n",
    "            return 0.8; // Precision for procedures\n",
    "            \n",
    "        if (questionLower.Contains(\"compare\") || questionLower.Contains(\"different\"))\n",
    "            return 0.5; // Diversity for comparisons\n",
    "            \n",
    "        // Domain-based defaults\n",
    "        return domain.ToLowerInvariant() switch\n",
    "        {\n",
    "            \"support\" => 0.8,\n",
    "            \"research\" => 0.6,\n",
    "            \"legal\" => 0.9,\n",
    "            \"technical\" => 0.75,\n",
    "            _ => 0.7\n",
    "        };\n",
    "    }\n",
    "    \n",
    "    private async Task<List<DocumentCandidate>> RetrieveCandidatesAsync(Vector<double> queryEmbedding, int limit)\n",
    "    {\n",
    "        return _documents\n",
    "            .Select(doc => new DocumentCandidate\n",
    "            {\n",
    "                Id = doc.Id,\n",
    "                Title = doc.Title,\n",
    "                Content = doc.Content,\n",
    "                Embedding = doc.Embedding,\n",
    "                Score = 1.0 - Distance.Cosine(queryEmbedding.ToArray(), doc.Embedding.ToArray())\n",
    "            })\n",
    "            .OrderByDescending(d => d.Score)\n",
    "            .Take(limit)\n",
    "            .ToList();\n",
    "    }\n",
    "    \n",
    "    private string GenerateAnswer(string question, List<DocumentCandidate> documents)\n",
    "    {\n",
    "        return $\"Based on {documents.Count} diverse sources selected using MMR, here's the answer to '{question}': \" +\n",
    "               $\"[This would be generated by your LLM using the selected context. The MMR algorithm ensured \" +\n",
    "               $\"we have diverse, relevant information rather than repetitive similar documents.]\"; \n",
    "    }\n",
    "    \n",
    "    private List<DocumentCandidate> GenerateDocumentDatabase()\n",
    "    {\n",
    "        // Generate a diverse set of mock documents for demonstration\n",
    "        var documents = new List<DocumentCandidate>();\n",
    "        var random = new Random(42);\n",
    "        \n",
    "        var sampleContent = new[]\n",
    "        {\n",
    "            \"API authentication requires OAuth 2.0 tokens for secure access to endpoints.\",\n",
    "            \"Password reset instructions: Click 'Forgot Password' and follow email instructions.\",\n",
    "            \"Data privacy regulations require explicit consent for personal information collection.\",\n",
    "            \"System performance can be optimized through proper caching strategies.\",\n",
    "            \"Database indexing improves query performance significantly.\",\n",
    "            \"Load balancing distributes traffic across multiple servers.\",\n",
    "            \"Error handling should provide meaningful messages to users.\",\n",
    "            \"Code reviews help maintain quality and share knowledge.\",\n",
    "            \"Automated testing reduces bugs in production deployments.\",\n",
    "            \"Documentation should be kept up-to-date with code changes.\"\n",
    "        };\n",
    "        \n",
    "        for (int i = 0; i < 30; i++)\n",
    "        {\n",
    "            var content = sampleContent[i % sampleContent.Length];\n",
    "            documents.Add(new DocumentCandidate\n",
    "            {\n",
    "                Id = $\"doc_{i:D3}\",\n",
    "                Title = $\"Document {i}: Technical Information\",\n",
    "                Content = content,\n",
    "                Embedding = Vector<double>.Build.Dense(384, j => random.NextDouble() - 0.5).Normalize(2)\n",
    "            });\n",
    "        }\n",
    "        \n",
    "        return documents;\n",
    "    }\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"‚úÖ Production RAG service implementation complete!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating the Production RAG Service\n",
    "\n",
    "Let's create an instance of our production RAG service and test it with different scenarios to see adaptive lambda selection and two-stage retrieval in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ PRODUCTION RAG SERVICE DEMONSTRATION\n",
      "Testing adaptive lambda selection and two-stage retrieval:\n",
      "\n",
      "üéØ Procedural query - should use high lambda\n",
      "Query: \"How to deploy a web application?\" (domain: technical)\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Processing question 4bfb9c81: How to deploy a web application? (domain: technical)\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Selected 5 documents using MMR (Œª=0.8) for 4bfb9c81\n",
      "‚úÖ Lambda used: 0.80\n",
      "üìÑ Documents selected: 5\n",
      "üíæ From cache: False\n",
      "üìù Answer preview: Based on 5 diverse sources selected using MMR, here's the answer to 'How to deploy a web application...\n",
      "\n",
      "üéØ Comparative query - should use balanced lambda\n",
      "Query: \"Compare different authentication methods\" (domain: research)\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Processing question 0c8ca2f8: Compare different authentication methods (domain: research)\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Selected 5 documents using MMR (Œª=0.5) for 0c8ca2f8\n",
      "‚úÖ Lambda used: 0.50\n",
      "üìÑ Documents selected: 5\n",
      "üíæ From cache: False\n",
      "üìù Answer preview: Based on 5 diverse sources selected using MMR, here's the answer to 'Compare different authenticatio...\n",
      "\n",
      "üéØ Support query - should use high precision lambda\n",
      "Query: \"My password reset isn't working\" (domain: support)\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Processing question 2e1a4194: My password reset isn't working (domain: support)\n",
      "‚úÖ Lambda used: 0.80\n",
      "üìÑ Documents selected: 5\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Selected 5 documents using MMR (Œª=0.8) for 2e1a4194\n",
      "üíæ From cache: False\n",
      "üìù Answer preview: Based on 5 diverse sources selected using MMR, here's the answer to 'My password reset isn't working...\n",
      "\n",
      "üéØ General query - should use default lambda\n",
      "Query: \"What are the latest trends in AI?\" (domain: general)\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Processing question 938c9ae9: What are the latest trends in AI? (domain: general)\n",
      "‚úÖ Lambda used: 0.70\n",
      "üìÑ Documents selected: 5\n",
      "üíæ From cache: False\n",
      "info: Submission#32.ProductionRAGService[0]\n",
      "      Selected 5 documents using MMR (Œª=0.7) for 938c9ae9\n",
      "üìù Answer preview: Based on 5 diverse sources selected using MMR, here's the answer to 'What are the latest trends in A...\n",
      "\n",
      "‚úÖ Production RAG service demonstration complete!\n"
     ]
    }
   ],
   "source": [
    "// Create and test the production RAG service\n",
    "// Set up dependency injection services\n",
    "var services = new ServiceCollection()\n",
    "    .AddMemoryCache()\n",
    "    .AddLogging(builder => builder.AddConsole())\n",
    "    .BuildServiceProvider();\n",
    "\n",
    "var cache = services.GetRequiredService<IMemoryCache>();\n",
    "var logger = services.GetRequiredService<ILogger<ProductionRAGService>>();\n",
    "var ragService = new ProductionRAGService(embeddingGenerator, cache, logger);\n",
    "\n",
    "Console.WriteLine(\"üöÄ PRODUCTION RAG SERVICE DEMONSTRATION\");\n",
    "Console.WriteLine(\"Testing adaptive lambda selection and two-stage retrieval:\\n\");\n",
    "\n",
    "// Test different query types to see adaptive lambda selection\n",
    "var testQueries = new[]\n",
    "{\n",
    "    (\"How to deploy a web application?\", \"technical\", \"Procedural query - should use high lambda\"),\n",
    "    (\"Compare different authentication methods\", \"research\", \"Comparative query - should use balanced lambda\"),\n",
    "    (\"My password reset isn't working\", \"support\", \"Support query - should use high precision lambda\"),\n",
    "    (\"What are the latest trends in AI?\", \"general\", \"General query - should use default lambda\")\n",
    "};\n",
    "\n",
    "foreach (var (question, domain, description) in testQueries)\n",
    "{\n",
    "    Console.WriteLine($\"üéØ {description}\");\n",
    "    Console.WriteLine($\"Query: \\\"{question}\\\" (domain: {domain})\");\n",
    "    \n",
    "    var response = await ragService.AskQuestionAsync(question, domain);\n",
    "    \n",
    "    Console.WriteLine($\"‚úÖ Lambda used: {response.Lambda:F2}\");\n",
    "    Console.WriteLine($\"üìÑ Documents selected: {response.SourceDocuments.Count}\");\n",
    "    Console.WriteLine($\"üíæ From cache: {response.FromCache}\");\n",
    "    Console.WriteLine($\"üìù Answer preview: {response.Answer[..Math.Min(100, response.Answer.Length)]}...\");\n",
    "    Console.WriteLine();\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"‚úÖ Production RAG service demonstration complete!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Stage Retrieval Pattern\n",
    "\n",
    "Let's demonstrate the two-stage retrieval pattern that's essential for production MMR implementations:\n",
    "\n",
    "1. **Stage 1**: Cast wide net - retrieve many candidates (25)\n",
    "2. **Stage 2**: Apply MMR - select diverse subset (5)\n",
    "\n",
    "This pattern gives you MMR's benefits without comparing every document in your database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ TWO-STAGE RETRIEVAL PATTERN DEMONSTRATION\n",
      "This is the pattern used in production RAG systems:\n",
      "\n",
      "üìä Total documents in database: 100\n",
      "üîç Query: \"API security best practices\"\n",
      "\n",
      "üìã STAGE 1: Broad Candidate Retrieval\n",
      "‚úÖ Retrieved 25 candidates from 100 total documents\n",
      "üìà Top candidate similarity: 0.175\n",
      "üìâ Lowest candidate similarity: 0.038\n",
      "‚úÖ Selected 5 diverse documents using MMR (Œª=0.7)\n",
      "\n",
      "üìö Final Selected Documents:\n",
      "   ‚Ä¢ Authentication Guide 73 (similarity: 0.175)\n",
      "   ‚Ä¢ Data Privacy Guide 43 (similarity: 0.150)\n",
      "   ‚Ä¢ API Security Guide 0 (similarity: 0.100)\n",
      "   ‚Ä¢ Data Privacy Guide 75 (similarity: 0.070)\n",
      "   ‚Ä¢ Authentication Guide 1 (similarity: 0.091)\n",
      "\n",
      "üéØ Topic diversity: 3 different topics covered\n",
      "\n",
      "üí° This two-stage approach scales to millions of documents while maintaining MMR benefits!\n"
     ]
    }
   ],
   "source": [
    "// Demonstrate two-stage retrieval pattern\n",
    "Console.WriteLine(\"üîÑ TWO-STAGE RETRIEVAL PATTERN DEMONSTRATION\");\n",
    "Console.WriteLine(\"This is the pattern used in production RAG systems:\\n\");\n",
    "\n",
    "var demoQuery = \"API security best practices\";\n",
    "var demoQueryEmbedding = await embeddingGenerator.GenerateVectorAsync(demoQuery);\n",
    "\n",
    "// Simulate a larger document database\n",
    "var largeDocumentSet = new List<DocumentCandidate>();\n",
    "var random = new Random(42);\n",
    "var topics = new[] { \"API Security\", \"Authentication\", \"Authorization\", \"Data Privacy\", \"Performance\", \"Monitoring\", \"Testing\", \"Documentation\" };\n",
    "\n",
    "for (int i = 0; i < 100; i++)\n",
    "{\n",
    "    var topic = topics[i % topics.Length];\n",
    "    largeDocumentSet.Add(new DocumentCandidate\n",
    "    {\n",
    "        Id = $\"large_doc_{i:D3}\",\n",
    "        Title = $\"{topic} Guide {i}\",\n",
    "        Content = $\"This document covers {topic.ToLower()} concepts and best practices for enterprise applications.\",\n",
    "        Embedding = Vector<double>.Build.Dense(384, j => random.NextDouble() - 0.5).Normalize(2)\n",
    "    });\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"üìä Total documents in database: {largeDocumentSet.Count}\");\n",
    "Console.WriteLine($\"üîç Query: \\\"{demoQuery}\\\"\");\n",
    "\n",
    "// Stage 1: Broad retrieval\n",
    "Console.WriteLine(\"\\nüìã STAGE 1: Broad Candidate Retrieval\");\n",
    "var demoQueryVector = demoQueryEmbedding.ToArray().Select(f => (double)f).ToArray();\n",
    "var broadCandidates = largeDocumentSet\n",
    "    .Select(doc => new DocumentCandidate\n",
    "    {\n",
    "        Id = doc.Id,\n",
    "        Title = doc.Title,\n",
    "        Content = doc.Content,\n",
    "        Embedding = doc.Embedding,\n",
    "        Score = 1.0 - Distance.Cosine(demoQueryVector, doc.Embedding.ToArray())\n",
    "    })\n",
    "    .OrderByDescending(d => d.Score)\n",
    "    .Take(25)\n",
    "    .ToList();\n",
    "\n",
    "Console.WriteLine($\"‚úÖ Retrieved {broadCandidates.Count} candidates from {largeDocumentSet.Count} total documents\");\n",
    "Console.WriteLine($\"üìà Top candidate similarity: {broadCandidates.First().Score:F3}\");\n",
    "Console.WriteLine($\"üìâ Lowest candidate similarity: {broadCandidates.Last().Score:F3}\");\n",
    "\n",
    "// Stage 2: MMR selection\n",
    "var demoQueryVectorForMMR = Vector<double>.Build.DenseOfArray(demoQueryVector);\n",
    "var mmrSelected = MaximumMarginalRelevance.ComputeMMR(\n",
    "    vectors: broadCandidates.Select(c => c.Embedding).ToList(),\n",
    "    query: demoQueryVectorForMMR,\n",
    "    lambda: 0.7,\n",
    "    topK: 5\n",
    ");\n",
    "\n",
    "var finalDocuments = mmrSelected.Select(doc => broadCandidates[doc.index]).ToList();\n",
    "\n",
    "Console.WriteLine($\"‚úÖ Selected {finalDocuments.Count} diverse documents using MMR (Œª=0.7)\");\n",
    "Console.WriteLine(\"\\nüìö Final Selected Documents:\");\n",
    "foreach (var doc in finalDocuments)\n",
    "{\n",
    "    Console.WriteLine($\"   ‚Ä¢ {doc.Title} (similarity: {doc.Score:F3})\");\n",
    "}\n",
    "\n",
    "// Show topic diversity\n",
    "var selectedTopics = finalDocuments.Select(d => d.Title.Split(' ')[0]).Distinct().Count();\n",
    "Console.WriteLine($\"\\nüéØ Topic diversity: {selectedTopics} different topics covered\");\n",
    "Console.WriteLine(\"\\nüí° This two-stage approach scales to millions of documents while maintaining MMR benefits!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights and Best Practices üí°\n",
    "\n",
    "From our comprehensive exploration, here are the key takeaways for implementing MMR in production RAG systems:\n",
    "\n",
    "### 1. The MMR Advantage\n",
    "- **Solves Clustering Problem**: Prevents repetitive, similar results\n",
    "- **Improves User Experience**: Provides comprehensive, diverse information\n",
    "- **Reduces Follow-up Questions**: Users get complete answers upfront\n",
    "\n",
    "### 2. Lambda Selection Strategy\n",
    "- **Œª = 0.8-0.9**: High precision domains (support, legal, medical)\n",
    "- **Œª = 0.7**: General-purpose applications (recommended starting point)\n",
    "- **Œª = 0.5-0.6**: Research and comparative analysis\n",
    "- **Œª = 0.3-0.4**: Content discovery and exploration\n",
    "\n",
    "### 3. Production Patterns\n",
    "- **Two-Stage Retrieval**: Essential for scalability\n",
    "- **Adaptive Lambda**: Query and domain-based selection\n",
    "- **Intelligent Caching**: Improves performance significantly\n",
    "- **Comprehensive Logging**: Critical for monitoring and optimization\n",
    "\n",
    "### 4. MEAI Integration Benefits\n",
    "- **Standardized Interface**: Consistent embedding generation\n",
    "- **Azure OpenAI Support**: Production-ready embedding models\n",
    "- **Fallback Mechanisms**: Graceful degradation for offline scenarios\n",
    "- **Dependency Injection**: Clean, testable architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Applications üåç\n",
    "\n",
    "MMR's relevance-diversity balance improves many AI applications beyond traditional RAG:\n",
    "\n",
    "### E-commerce Recommendations\n",
    "Instead of 10 similar smartphones, users get phones, cases, chargers, and accessories.\n",
    "\n",
    "### Content Curation\n",
    "A tech newsletter about \"AI developments\" covers language models, computer vision, robotics, ethics, and applications instead of 5 ChatGPT articles.\n",
    "\n",
    "### Research Discovery\n",
    "\"Machine learning optimization\" returns papers on different techniques, domains, and evaluation metrics.\n",
    "\n",
    "### Customer Support\n",
    "Support tickets get diverse solution approaches: basic fixes, system compatibility, and escalation paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Your Implementation üöÄ\n",
    "\n",
    "Ready to implement MMR in your RAG system? Here's your roadmap:\n",
    "\n",
    "### 1. Start Simple\n",
    "- Begin with Œª = 0.7 for general use\n",
    "- Replace one retrieval call initially\n",
    "- Measure before expanding\n",
    "\n",
    "### 2. Integrate MEAI\n",
    "- Replace mock embeddings with Azure OpenAI\n",
    "- Use `text-embedding-3-small` for production\n",
    "- Implement proper error handling and retries\n",
    "\n",
    "### 3. Add Production Features\n",
    "- Implement two-stage retrieval pattern\n",
    "- Add adaptive lambda selection\n",
    "- Set up caching and monitoring\n",
    "\n",
    "### 4. Monitor and Optimize\n",
    "- Track user satisfaction and task completion\n",
    "- Monitor topic diversity in responses\n",
    "- A/B test different lambda values\n",
    "- Measure follow-up question rates\n",
    "\n",
    "### 5. Scale Thoughtfully\n",
    "- Use distributed caching (Redis)\n",
    "- Implement connection pooling\n",
    "- Add circuit breakers for resilience\n",
    "- Monitor performance and costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion üéâ\n",
    "\n",
    "Congratulations! You've completed a comprehensive journey through Maximum Marginal Relevance and its transformative impact on RAG systems.\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "- ‚úÖ **Understood the Problem**: Identified why traditional RAG falls short\n",
    "- ‚úÖ **Learned MMR Theory**: Mastered the relevance-diversity balance\n",
    "- ‚úÖ **Implemented with MEAI**: Built production-ready integration\n",
    "- ‚úÖ **Explored Real Examples**: Saw MMR solve actual clustering problems\n",
    "- ‚úÖ **Mastered Lambda Tuning**: Learned when to use different values\n",
    "- ‚úÖ **Built Production Patterns**: Implemented scalable, enterprise-ready solutions\n",
    "\n",
    "### The Real Impact\n",
    "\n",
    "MMR isn't just a technical optimization‚Äîit fundamentally improves user experience. Instead of repetitive responses, users get comprehensive information. Instead of follow-up questions, they get thorough coverage upfront.\n",
    "\n",
    "### Your RAG System Now\n",
    "\n",
    "With MMR integration, your RAG system:\n",
    "- **Avoids Information Clustering**: Diverse perspectives in every response\n",
    "- **Adapts to Use Cases**: Different domains get optimized behavior\n",
    "- **Scales with Demand**: Production patterns support growth\n",
    "- **Provides Insights**: Comprehensive observability enables optimization\n",
    "\n",
    "**The goal isn't just implementing a new algorithm‚Äîit's building AI systems that genuinely help people accomplish their goals. MMR is one powerful technique to get you there.**\n",
    "\n",
    "---\n",
    "\n",
    "*Ready to transform your RAG system? Start with Œª = 0.7 and watch your users get the comprehensive, diverse answers they deserve!* üöÄ‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
